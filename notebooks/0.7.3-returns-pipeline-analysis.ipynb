{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Sci-kit Learn\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# thermidor\n",
    "from thermidor import EstimatorSocketCV\n",
    "from thermidor import ClustererSocket\n",
    "from thermidor import date_extractor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we study capital as it flows through the American equity markets. Using daily returns and volume data we develop a method to identify regimes in the markets over time, regimes which characterize much of the markets' behavior. Using the segmentation of the data we may analyze the causes of market behavior associated with a given regime, and we can study how new developments in the world affect the behavior of capital. We may, for example, analyze all news associated with days belonging to a common regime to find topics which reoccur in time and infer how these topics influence the markets.\n",
    "\n",
    "The main intuition underpinning this project is that the financial markets, as the conduits of capital, act as \"encoders\" recording the behavior of capital in the face of new information. This information is encoded in the price histories of the instruments traded on the markets. \n",
    "\n",
    "Although this encoding allows for the potential to study the behavior of capital, since historical daily volume and returns data is available through [certain sources](http://www.crsp.com/products/research-products/crsp-us-stock-databases), it also poses a challenge in that this information is both high-dimensional and potentially extremely noisy. The high-dimensionality is a result of the number of equities actively traded in American markets &mdash; several thousand &mdash; and the low signal-to-noise-ratio results from the fact that market participants hold diverse beliefs, behave differently in the face of new information, and trade for many reasons \\[hence much market activity is not clearly associated with exogeneous changes in the world\\].\n",
    "\n",
    "Given these challenges, if we are to derive useful information from the markets we must dramatically reduce the dimensionality of the problem and minimize the effects of noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to create a Sci-kit Learn pipeline which takes in the raw daily returns data for a universe of assets, associates the data with a set of clusters \\[i.e. components or regimes\\], and returns this as a dataframe that can be used in future applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline itself consists of three major components in the following order:\n",
    "\n",
    "1. A data processor which takes the [raw data](http://www.crsp.com/products/research-products/crsp-us-stock-databases) and transforms it for use in the subsequent steps.\n",
    "\n",
    "2. A method to estimate the number of clusters in the data. This method uses cross-validation to select \n",
    "    - The dimensionality of a principal components decomposition used to reduce noise in the data and to signifigantly reduce the data's dimensionality\n",
    "    - The number of components \\[or distributions\\] to fit in a Gaussian mixture model. This model is used to find the means for each component, which are then passed to the final step\n",
    "    \n",
    "3. A method to segment the data. Using the estimated number of components found by cross-validation on the Gaussian mixture model in the previous step, and the the estimated component means, we use K-Means to segment the \\[transformed\\] data space, initializing the clusters' centers at the component means. We then assign each date to the cluster whose center it's nearest, and store this in a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in the flow of capital through the markets rather than the movement of the asset prices themselves, we weight daily returns data by the total dollar amount traded in the asset on that particular day as a function of the total dollar amount traded in the market. More concretely, we transform the data by:\n",
    "\n",
    "1. Calculating the midpoint price $$m_{i,j} = \\frac{h_{i,j} - l_{i,j}}{2}$$ where $h_{i,j}, \\ l_{i,j}$ are the high and low prices, respectively, for asset $j$ on day $i$. We use this midprice because we do not have access to the [volume-weighted average price data](http://www.crsp.com/products/documentation/data-definitions-2).\n",
    "\n",
    "2. Calculating the midprice dollar-value traded: $$p_{i,j} = m_{i,j} \\cdot v_{i,j}$$ where $v_{i,j}$ is the volume traded in asset $j$ on day $i$.\n",
    "\n",
    "3. Calculating the percentage of the total dollar-value traded in asset $j$ on day $i$: $$s_{i,j} = \\frac{p_{i,j}}{\\sum_{k=1}^N p_{i,k}}$$ where $N$ is the number of assets in the universe.\n",
    "\n",
    "4. Calculating the weighted return: $$x_{i,j} = \\alpha \\cdot s_{i,j} \\cdot r_{i,j}$$ where $\\alpha$ is a scalar, and $r_{i,j}$ is return of asset $j$ on day $i$. \n",
    "\n",
    "We calculate these values and store them in an $m \\times N$ design matrix where $m$ is the number of days in the data and $N$ is the number of assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_returns(df, alpha=1.0):\n",
    "    '''Extracts weighted returns data from\n",
    "    CRSP raw data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : array-like\n",
    "    \n",
    "    alpha : float, optional default=1.0\n",
    "        Real number to multiply weighted returns by.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Pandas dataframe containing weighted returns.\n",
    "    '''\n",
    "    # Pivot the raw data since assets are stacked\n",
    "    df = pd.pivot(df, \n",
    "                  values = ['BIDLO', 'ASKHI', 'VOL', 'RETX'], \n",
    "                  index='date', columns = 'PERMNO'\n",
    "                 )\n",
    "    \n",
    "    # Infers objects; those that can't be inferred are\n",
    "    # converted to `NaN`\n",
    "    df = df.convert_objects(convert_numeric=True)\n",
    "    \n",
    "    # Replace all missing entries with '0'\n",
    "    df.replace('NaN',0)\n",
    "    \n",
    "    # Functions for `vectorize` to apply elementwise to\n",
    "    # pairs of elements from columns\n",
    "    average = lambda x, y : ((x + y) / 2.0)\n",
    "    \n",
    "    multiply = lambda x, y : (x * y)\n",
    "    \n",
    "    divide = lambda x, y : (x / y)\n",
    "    \n",
    "    permnos = df['RETX'].columns.tolist()\n",
    "    \n",
    "    for permno in permnos:\n",
    "        # Step 1 - Calculate midprice\n",
    "        df[('MIDPRCE', permno)] = np.vectorize(average)(df[('ASKHI', permno)],\n",
    "                                                        df[('BIDLO', permno)])\n",
    "        \n",
    "        # Step 2 - Calculate midprice dollar-value traded\n",
    "        df[('DLRTRDED', permno)] = np.vectorize(multiply)(df[('MIDPRCE', permno)],\n",
    "                                                          df[('VOL', permno)])\n",
    "        \n",
    "    # Sum total dollar-value traded by day\n",
    "    df['TTLDLRTRDED'] = df['DLRTRDED'].sum(axis=1)\n",
    "    \n",
    "    # Drop indexes containing '0' entries in 'TTLDLRTRDED'\n",
    "    # These are days with no market activity\n",
    "    df.drop(df.index[df['TTLDLRTRDED'] == 0], inplace=True)\n",
    "    \n",
    "    for permno in permnos:\n",
    "        # Step 3 - Calculate the percentage of total dollar-value traded\n",
    "        df[('PRCNTDLRTRDED', permno)] = np.vectorize(divide)(df[('DLRTRDED', permno)], \n",
    "                                                             df['TTLDLRTRDED'])\n",
    "        \n",
    "        # Step 4 - Calculate weighted return\n",
    "        df[('WGHTEDRETX', permno)] = alpha * np.vectorize(multiply)(\n",
    "            df[('PRCNTDLRTRDED', permno)], df[('RETX', permno)])\n",
    "    \n",
    "    # Sort dataframe by PERMNO\n",
    "    df = df.sort_index(axis=1, level=1)\n",
    "    \n",
    "    # Only return weighted returns\n",
    "    X = df['WGHTEDRETX']\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source of heterogeneity in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify two sources of heterogeneity in the data:\n",
    "\n",
    "1. Asset returns are fat-tailed\n",
    "\n",
    "2. Correlations between asset returns are dynamic\n",
    "\n",
    "We provide evidence for both below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of asset returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the non-normality of asset returns, we begin by looking at the distribution of weighted returns for two different assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    }
   ],
   "source": [
    "# Import raw data\n",
    "spdata = pd.read_csv('../data/crsp-raw-data/spdata-2007-2019.csv')\n",
    "\n",
    "# Transform data\n",
    "X = transform_returns(spdata, alpha=1.0)\n",
    "\n",
    "# First asset - first in data\n",
    "x1 = X.iloc[:,0]\n",
    "\n",
    "# Second asset - 370th in data, randomly chosen\n",
    "x2 = X.iloc[:,369]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, tight_layout=True)\n",
    "\n",
    "# Create plots of the weighted asset returns\n",
    "axs[0].hist(x1, bins=300, log=True) # Use log trans since \n",
    "axs[1].hist(x2, bins=300, log=True) # since data is highly\n",
    "plt.show()                          # peaked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QQ-plot for asset 1\n",
    "stats.probplot(x1, plot=plt)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QQ-plot for asset 2\n",
    "stats.probplot(x2, plot=plt)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see remarkably [fat tails](https://seankross.com/2016/02/29/A-Q-Q-Plot-Dissection-Kit.html) in both cases. Next let's compare these plots to the unweighted returns data for these two assets. We first transform the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Pivot the raw data since assets are stacked\n",
    "unweighted_ret = pd.pivot(spdata, \n",
    "                          values = ['BIDLO', 'ASKHI', 'VOL', 'RETX'], \n",
    "                          index='date', columns = 'PERMNO')\n",
    "    \n",
    "# Infers objects; those that can't be inferred are\n",
    "# converted to `NaN`\n",
    "unweighted_ret = unweighted_ret.convert_objects(convert_numeric=True)\n",
    "    \n",
    "# Replace all missing entries with '0'\n",
    "unweighted_ret = unweighted_ret.replace('NaN',0)\n",
    "    \n",
    "# We're only insterested in returns\n",
    "unweighted_ret = unweighted_ret['RETX']\n",
    "\n",
    "# First asset - first in data\n",
    "x1_raw = unweighted_ret.iloc[:,0]\n",
    "\n",
    "# Second asset - 370th in data, randomly chosen\n",
    "x2_raw = unweighted_ret.iloc[:,369]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/histograms.py:824: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/histograms.py:825: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, tight_layout=True)\n",
    "\n",
    "# Create plots of the raw asset returns\n",
    "axs[0].hist(x1_raw, bins=300, log=True) # Use log trans since \n",
    "axs[1].hist(x2_raw, bins=300, log=True) # since data is highly\n",
    "plt.show()                              # peaked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QQ-plot for asset 1\n",
    "stats.probplot(x1_raw, plot=plt)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QQ-plot for asset 2\n",
    "stats.probplot(x2_raw, plot=plt)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the unweighted returns, we still see evidence for fat-tails, or [leptokurtosis](https://en.wikipedia.org/wiki/Kurtosis). This is consistent with [previous work](https://www.longin.fr//Recherche_Publications/Articles_pdf/Longin_The_choice_of_the_distribution_of_asset_returns.pdf#page=2), which has found that asset returns often indeed exhibit leptokurtosis.\n",
    "\n",
    "In light of this we must consider whether we are justified in employing a Gaussian mixture model to estimate the density of data which appears to be non-normal. To answer this question, consider what this data represents. These are the daily returns for an asset over a period of more than twelve years. This period includes both an extremely pronounced economic recession and a long, sustained period of economic growth. It seems likely then that these assets' returns actually contain multiple \"regimes\", each associated with its own mean and variance. Therefore it makes since to view each asset's return history as a mixture of Gaussians.\n",
    "\n",
    "To confirm our assumption that asset returns are leptokurtic, we calculate the kurtosis for a sample of the assets in the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.825553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.234459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.393829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.483380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.595756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>175.202549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.834397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.587304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.583731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34.317811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Kurtosis\n",
       "0    6.825553\n",
       "1   10.234459\n",
       "2    9.393829\n",
       "3    5.483380\n",
       "4   12.595756\n",
       "5  175.202549\n",
       "6    8.834397\n",
       "7    8.587304\n",
       "8   14.583731\n",
       "9   34.317811"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate kurtosis for raw returns data\n",
    "raw_kurt = pd.DataFrame(stats.kurtosis(\n",
    "    unweighted_ret, bias=False, nan_policy='omit'), columns={'Kurtosis'})\n",
    "\n",
    "raw_kurt[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all assets in this sample exhibit kurtoses greater than 0, which [confirms](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kurtosis.html) that the sample distributions are fat-tailed. \n",
    "\n",
    "We next calculate the kurtosis for the same sample of assets using the weighted returns data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207.827455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.925747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.945770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180.599143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.253828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>181.924157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>364.984546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>155.453199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62.616346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>870.343376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Kurtosis\n",
       "0  207.827455\n",
       "1   95.925747\n",
       "2   26.945770\n",
       "3  180.599143\n",
       "4   65.253828\n",
       "5  181.924157\n",
       "6  364.984546\n",
       "7  155.453199\n",
       "8   62.616346\n",
       "9  870.343376"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate kurtosis for weighted returns data\n",
    "X_kurt = pd.DataFrame(\n",
    "    stats.kurtosis(X, bias=False, nan_policy='omit'), columns={'Kurtosis'})\n",
    "\n",
    "X_kurt[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in all cases kurtosis is increased signifigantly by the data transformation. Intuitively this makes sense, since we would expect large returns are associated with large volumes. Indeed, research [provides strong evidence](https://www.cjournal.cz/files/65.pdf) for this intuition.\n",
    "\n",
    "In our case we weighted the returns data for each asset by the dollar-value traded in that instrument, a transformation which essentially maximizes outliers and minimizes inliers, as seen in the histograms above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic asset correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only are the returns for each asset associated with multiple regimes, but the correlation between assets is clearly non-constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PERMNO</th>\n",
       "      <th>10104</th>\n",
       "      <th>10107</th>\n",
       "      <th>10138</th>\n",
       "      <th>10145</th>\n",
       "      <th>10516</th>\n",
       "      <th>10623</th>\n",
       "      <th>10696</th>\n",
       "      <th>10909</th>\n",
       "      <th>11308</th>\n",
       "      <th>11403</th>\n",
       "      <th>...</th>\n",
       "      <th>92611</th>\n",
       "      <th>92614</th>\n",
       "      <th>92624</th>\n",
       "      <th>92655</th>\n",
       "      <th>92778</th>\n",
       "      <th>93002</th>\n",
       "      <th>93089</th>\n",
       "      <th>93096</th>\n",
       "      <th>93132</th>\n",
       "      <th>93429</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318289</td>\n",
       "      <td>0.361920</td>\n",
       "      <td>0.387020</td>\n",
       "      <td>0.243160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.339363</td>\n",
       "      <td>0.170941</td>\n",
       "      <td>0.294044</td>\n",
       "      <td>0.089385</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.205125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.318289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.435810</td>\n",
       "      <td>0.338496</td>\n",
       "      <td>0.179704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.349383</td>\n",
       "      <td>0.155571</td>\n",
       "      <td>0.341893</td>\n",
       "      <td>0.050365</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.361920</td>\n",
       "      <td>0.435810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.520426</td>\n",
       "      <td>0.285873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488194</td>\n",
       "      <td>0.188603</td>\n",
       "      <td>0.352470</td>\n",
       "      <td>0.137617</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.387020</td>\n",
       "      <td>0.338496</td>\n",
       "      <td>0.520426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.292635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.462795</td>\n",
       "      <td>0.176893</td>\n",
       "      <td>0.372460</td>\n",
       "      <td>0.089967</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.260053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243160</td>\n",
       "      <td>0.179704</td>\n",
       "      <td>0.285873</td>\n",
       "      <td>0.292635</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.221538</td>\n",
       "      <td>0.105389</td>\n",
       "      <td>0.264910</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.150736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "PERMNO     10104     10107     10138     10145     10516  10623     10696  \\\n",
       "0       1.000000  0.318289  0.361920  0.387020  0.243160    NaN  0.339363   \n",
       "1       0.318289  1.000000  0.435810  0.338496  0.179704    NaN  0.349383   \n",
       "2       0.361920  0.435810  1.000000  0.520426  0.285873    NaN  0.488194   \n",
       "3       0.387020  0.338496  0.520426  1.000000  0.292635    NaN  0.462795   \n",
       "4       0.243160  0.179704  0.285873  0.292635  1.000000    NaN  0.221538   \n",
       "\n",
       "PERMNO     10909     11308     11403  ...  92611  92614  92624     92655  \\\n",
       "0       0.170941  0.294044  0.089385  ...    NaN    NaN    NaN  0.205125   \n",
       "1       0.155571  0.341893  0.050365  ...    NaN    NaN    NaN  0.143239   \n",
       "2       0.188603  0.352470  0.137617  ...    NaN    NaN    NaN  0.189089   \n",
       "3       0.176893  0.372460  0.089967  ...    NaN    NaN    NaN  0.260053   \n",
       "4       0.105389  0.264910  0.072102  ...    NaN    NaN    NaN  0.150736   \n",
       "\n",
       "PERMNO  92778  93002  93089  93096  93132  93429  \n",
       "0         NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "1         NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2         NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "3         NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "4         NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation between assets using the first 1200 days\n",
    "corr_matrix_1 = pd.DataFrame(np.corrcoef(X.iloc[:1200,:].T), columns=X.columns)\n",
    "\n",
    "corr_matrix_1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PERMNO</th>\n",
       "      <th>10104</th>\n",
       "      <th>10107</th>\n",
       "      <th>10138</th>\n",
       "      <th>10145</th>\n",
       "      <th>10516</th>\n",
       "      <th>10623</th>\n",
       "      <th>10696</th>\n",
       "      <th>10909</th>\n",
       "      <th>11308</th>\n",
       "      <th>11403</th>\n",
       "      <th>...</th>\n",
       "      <th>92611</th>\n",
       "      <th>92614</th>\n",
       "      <th>92624</th>\n",
       "      <th>92655</th>\n",
       "      <th>92778</th>\n",
       "      <th>93002</th>\n",
       "      <th>93089</th>\n",
       "      <th>93096</th>\n",
       "      <th>93132</th>\n",
       "      <th>93429</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088739</td>\n",
       "      <td>0.203242</td>\n",
       "      <td>0.176314</td>\n",
       "      <td>0.098402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.126675</td>\n",
       "      <td>0.062620</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>0.087129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086629</td>\n",
       "      <td>0.011925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071391</td>\n",
       "      <td>0.073866</td>\n",
       "      <td>0.065523</td>\n",
       "      <td>0.038870</td>\n",
       "      <td>0.012727</td>\n",
       "      <td>0.099276</td>\n",
       "      <td>0.047625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088739</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.171994</td>\n",
       "      <td>0.198238</td>\n",
       "      <td>0.105657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.182473</td>\n",
       "      <td>0.076407</td>\n",
       "      <td>0.108210</td>\n",
       "      <td>0.086355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111222</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097059</td>\n",
       "      <td>0.071977</td>\n",
       "      <td>0.095556</td>\n",
       "      <td>0.025867</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>-0.033410</td>\n",
       "      <td>0.093001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.203242</td>\n",
       "      <td>0.171994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.507124</td>\n",
       "      <td>0.340276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432477</td>\n",
       "      <td>0.146871</td>\n",
       "      <td>0.283729</td>\n",
       "      <td>0.272391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231519</td>\n",
       "      <td>0.056455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.201156</td>\n",
       "      <td>0.189649</td>\n",
       "      <td>0.175310</td>\n",
       "      <td>0.102320</td>\n",
       "      <td>0.059348</td>\n",
       "      <td>0.043520</td>\n",
       "      <td>0.145527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.176314</td>\n",
       "      <td>0.198238</td>\n",
       "      <td>0.507124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.449842</td>\n",
       "      <td>0.131344</td>\n",
       "      <td>0.254172</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246170</td>\n",
       "      <td>0.062846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.215172</td>\n",
       "      <td>0.223421</td>\n",
       "      <td>0.204401</td>\n",
       "      <td>0.117115</td>\n",
       "      <td>0.064267</td>\n",
       "      <td>0.082186</td>\n",
       "      <td>0.125902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.098402</td>\n",
       "      <td>0.105657</td>\n",
       "      <td>0.340276</td>\n",
       "      <td>0.323634</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.303221</td>\n",
       "      <td>0.143740</td>\n",
       "      <td>0.227177</td>\n",
       "      <td>0.123069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143839</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.197041</td>\n",
       "      <td>0.099754</td>\n",
       "      <td>0.118164</td>\n",
       "      <td>0.084553</td>\n",
       "      <td>0.022039</td>\n",
       "      <td>0.081007</td>\n",
       "      <td>0.054989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "PERMNO     10104     10107     10138     10145     10516  10623     10696  \\\n",
       "0       1.000000  0.088739  0.203242  0.176314  0.098402    NaN  0.126675   \n",
       "1       0.088739  1.000000  0.171994  0.198238  0.105657    NaN  0.182473   \n",
       "2       0.203242  0.171994  1.000000  0.507124  0.340276    NaN  0.432477   \n",
       "3       0.176314  0.198238  0.507124  1.000000  0.323634    NaN  0.449842   \n",
       "4       0.098402  0.105657  0.340276  0.323634  1.000000    NaN  0.303221   \n",
       "\n",
       "PERMNO     10909     11308     11403  ...     92611     92614  92624  \\\n",
       "0       0.062620  0.035406  0.087129  ...  0.086629  0.011925    NaN   \n",
       "1       0.076407  0.108210  0.086355  ...  0.111222  0.038374    NaN   \n",
       "2       0.146871  0.283729  0.272391  ...  0.231519  0.056455    NaN   \n",
       "3       0.131344  0.254172  0.207843  ...  0.246170  0.062846    NaN   \n",
       "4       0.143740  0.227177  0.123069  ...  0.143839  0.046829    NaN   \n",
       "\n",
       "PERMNO     92655     92778     93002     93089     93096     93132     93429  \n",
       "0       0.071391  0.073866  0.065523  0.038870  0.012727  0.099276  0.047625  \n",
       "1       0.097059  0.071977  0.095556  0.025867  0.007198 -0.033410  0.093001  \n",
       "2       0.201156  0.189649  0.175310  0.102320  0.059348  0.043520  0.145527  \n",
       "3       0.215172  0.223421  0.204401  0.117115  0.064267  0.082186  0.125902  \n",
       "4       0.197041  0.099754  0.118164  0.084553  0.022039  0.081007  0.054989  \n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation between assets using the next 1200 days\n",
    "corr_matrix_2 = pd.DataFrame(np.corrcoef(X.iloc[1200:2400,:].T), columns=X.columns)\n",
    "\n",
    "corr_matrix_2.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`corr_matrix_1` is calculated using the first 1200 days of returns data, and `corr_matrix_2` is calculated using the next 1200 days. We see that the correlations between assets in the second matrix are very different in comparison to their counterparts in the first matrix.\n",
    "\n",
    "The dynamic nature of the correlations among assets in time implies that these correlations themselves experience regimes. We will attempt to infer these regimes from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal component analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick inspection of the correlation matrices for the data shows that a certain degree of correlation exists among many assets' returns. This inherent correlation suggests that we should use some decomposition scheme to minimize correlation among the predictors. \n",
    "\n",
    "Another reason for decomposition is that less liquid assets are likely to exhibit much greater variance in returns &mdash; or volatility &mdash; than more liquid assets, even when there is no apparent exogeneous cause for price movement. For the purposes of this project, this endogeneous volatility may be viewed as noise which needs to be minimized. Hence the need for decomposition.\n",
    "\n",
    "Both of these facts suggest that a principal components decomposition of the weighted returns data is appropriate. To perform a principal components decomposition we must provide the algorithm with a parameter `n_components`, the number of components to keep from the decomposition. We use the method of maximum likelihood estimation to determine this value.\n",
    "\n",
    "Using the [probabilistic PCA model](http://www.miketipping.com/papers/met-mppca.pdf#page=5) we may derive a log-likelihood for our data given the parameters of the model, including the number of principal components retained. We may then use cross-validation to estimate the out-of-sample log-likelihood for a set of PCA models and compare their performance, selecting the model the greatest out of sample log-likelihood.\n",
    "\n",
    "Since we have no reason to believe that any certain number of components to retain in the model is superior, we use [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV.score) with a uniform distribution for `n_components` from 1 to the `min(n_samples, n_features)` of the data matrix. In this way the grid search method is free to choose any number of components to retain. We use this function since LAPACK, the SVD solver used by [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html), is demanding with regards to the dimensionality of the data matrix on which it operates. Because we need to calculate this value on the transformed array in the pipeline we implement this step using `EstimatorSocketCV` from `thermidor`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_dist(df, proportion=.8):\n",
    "    '''Creates scipy randint distribution\n",
    "    with max=min(n_samples, n_features) of\n",
    "    df.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : array-like\n",
    "    \n",
    "    proportion : float, optional default=.8\n",
    "        Determines the maximum of the range for the distribution.\n",
    "        Defaults to .8 since 5-fold cross-validation uses at most \n",
    "        80 percent of the data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    scipy.stats object\n",
    "    '''\n",
    "    n_samples = df.shape[0] * proportion\n",
    "    \n",
    "    n_features = df.shape[1]\n",
    "    \n",
    "    dist_max = min(n_samples, n_features)\n",
    "    \n",
    "    return randint(1, dist_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See:\n",
    "# https://github.com/rcorrero/thermidor/blob/master/thermidor/classes/estimator_socket_cv.py\n",
    "decomposer = EstimatorSocketCV(estimator=PCA(), param_name='n_components',\n",
    "                               dist_func=pca_dist, cross_val=RandomizedSearchCV,\n",
    "                               cv=5, n_jobs=-1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian mixture model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our data has been successfully decomposed, we must then estimate the number of groups contained within the data. To do so, we use a [Gaussian mixture model](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html).\n",
    "\n",
    "This model treats the distribution of the daily weighted returns as a mixture of $k$ Gaussian distributions, each with its own covariance matrix and mean. Using the method of [expectation-maximization](https://en.wikipedia.org/wiki/Expectation–maximization_algorithm) the model estimates the means and covariances of the distributions by choosing those values which maximize the log-likelihood of the data \\[see [_Elements of Statistical Learning_](https://web.stanford.edu/~hastie/ElemStatLearn/) for more about expectation-maximization and the Gaussian mixture model\\].\n",
    "\n",
    "This algorithm, like the principal components algorithm, yields a log-likelihood value which may be used to compare models with different parameters. We use this log-likelihood to compare models with different values $k$ to find an optimum. This is done using cross-validation.\n",
    "\n",
    "Once again, we have no prior knowledge of the true number of regimes contained within the data, but we would prefer that $k$ be both large enough to allow for meaniningful segmentation of the data and yet small enough that all clusters are relatively dense, that is, contain many data points. We therefore use [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV.score) with a uniform distribution for $k$ ranging from 1 to 300, approximately one-tenth the number of dates in the data. If the value chosen for $k$ is a boundary value, i.e. the smallest or largest $k$ in the sample of $k$ values, then we must modify our model. If the smallest $k$ is found to be optimal, then we have strong evidence that there is no meaningful clustering of the data possible, and if the largest $k$ is chosen then we need to extend the range for $k$ to include larger values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the number of clusters using `GaussianmixtureModel` we create a bespoke class `GMMSocketCV` which inherits from [`EstimatorSocketCV`](https://github.com/rcorrero/thermidor/blob/master/thermidor/classes/estimator_socket_cv.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See:\n",
    "# https://github.com/rcorrero/thermidor/blob/master/thermidor/classes/estimator_socket_cv.py\n",
    "class GMMSocketCV(EstimatorSocketCV):\n",
    "    '''Adds `means_` attribute for use in `returns_pipeline`.\n",
    "    '''\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        '''Fits estimator using `cross_val`.\n",
    "        '''\n",
    "        # Distribution passed to `cross_val`\n",
    "        self.dist = {\n",
    "            self.param_name : self.dist_func(X)\n",
    "        }\n",
    "        \n",
    "        # Create cross-validator object\n",
    "        self.model_selector = self.cross_val(self.estimator, self.dist,\n",
    "                                             cv=self.cv, n_jobs=self.n_jobs,\n",
    "                                             random_state=self.random_state,\n",
    "                                             verbose=self.verbose)\n",
    "        \n",
    "        self.model_selector.fit(X, y, **kwargs)\n",
    "        \n",
    "        # Store `best_estimator_`\n",
    "        self.best_estimator_ = self.model_selector.best_estimator_\n",
    "        \n",
    "        # Store `means_` for use in pipeline\n",
    "        self.means_ = self.best_estimator_.means_\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''Returns X.\n",
    "        \n",
    "        Implemented so that this estimator may be used\n",
    "        as intermediate step in pipeline.\n",
    "        '''\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class allows us to use `GaussianMixtureModel` as an intermediate step in a Sci-kit Learn pipeline, something which is not possible otherwise. This class also allows for easy extraction of `means_` from `GaussianMixtureModel` in future steps in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_dist(df, proportion=.8):\n",
    "    '''Creates scipy randint distribution\n",
    "    with max=(n_samples * proportion) of df.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : array-like\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    scipy.stats object\n",
    "    '''\n",
    "    # Determines the maximum of the range for the distribution\n",
    "    proportion = .1\n",
    "    \n",
    "    dist_max = df.shape[0] * proportion\n",
    "    \n",
    "    return randint(1, dist_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_estimator = GMMSocketCV(estimator=GaussianMixture(), \n",
    "                                      param_name='n_components',\n",
    "                                      dist_func=gmm_dist,\n",
    "                                      cross_val=RandomizedSearchCV,\n",
    "                                      cv=5, n_jobs=-1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once an appropriate value for $k$ has been found, we need to segment the data space such that the data in any region of the space may be associated with a specific cluster. To do so, we use [`KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans). \n",
    "\n",
    "K-means may be viewed as a kind of \"hard\" Gaussian mixture model in which the responsibility of a component for a data point is one for the component with mean closest to it, and the responsibility for all other components is zero \\[see [_Elements of Statistical Learning_](https://web.stanford.edu/~hastie/ElemStatLearn/) for a more rigorous comparison of Gaussian mixture models and K-means\\]. This model is useful in segmenting the data space so that data may be associated with clusters. The clusters may then be analyzed individually to identify similarities in the data.\n",
    "\n",
    "`KMeans` requires both `n_clusters`, the number of clusters to fit, and `init`, the initial cluster center locations in the data space. In our pipeline we obtain both of these parameters from the optimal Gaussian mixture model selected in the previous step. \n",
    "\n",
    "Once the data is segmented we create a dataframe in which each date in the data is associated with a \\(numbered\\) cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the segmentation step in our pipeline using `KMeans` we create a bespoke class `KMeansSocketCV` which also inherits from `ClustererSocket`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See:\n",
    "# https://github.com/rcorrero/thermidor/blob/master/thermidor/classes/clusterer_socket.py\n",
    "class KMeansSocket(ClustererSocket):\n",
    "    '''Class which allows for passing `means_`\n",
    "    into `KMeans` from `GaussianMixtureModel`\n",
    "    [or any other object which has a `means_`\n",
    "    attribute].\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    pca_name : string\n",
    "        Name of pipeline step from which `index_` is extracted.\n",
    "        \n",
    "    gmm_name : string\n",
    "            Name of pipeline step from which `means_` is extracted.\n",
    "            \n",
    "    labels_ : list of strings, optional default=None\n",
    "        Labels of each point.\n",
    "        \n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "        - None, to use the default 3-fold cross validation,\n",
    "        - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
    "        - :term:`CV splitter`,\n",
    "        - An iterable yielding (train, test) splits as arrays of indices.\n",
    "        For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
    "        either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
    "        other cases, :class:`KFold` is used.\n",
    "            \n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "            \n",
    "    random_state : int, RandomState instance or None, optional, default=None\n",
    "        Pseudo random number generator state used for random uniform sampling\n",
    "        from lists of possible values instead of scipy.stats distributions.\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`.\n",
    "            \n",
    "    verbose : integer\n",
    "        Controls the verbosity: the higher, the more messages.\n",
    "    '''\n",
    "    def __init__(self, pca_name=None, gmm_name=None, labels_=None,\n",
    "                 cv=3, n_jobs=None, random_state=None, verbose=False):\n",
    "        self.pca_name = pca_name\n",
    "        self.gmm_name = gmm_name\n",
    "        self.labels_ = labels_\n",
    "        \n",
    "        self.cv = cv\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        '''Fits `KMeans` using `means_`\n",
    "        from `gmm_name` step in pipeline.\n",
    "        '''\n",
    "        self.pipeline = returns_pipeline\n",
    "            \n",
    "        # Extract `means_` from previous step in pipeline\n",
    "        self._means = self.pipeline.named_steps[\n",
    "            self.gmm_name].means_\n",
    "        \n",
    "        # Calculate number of clusters\n",
    "        self.n_clusters = self._means.shape[0]\n",
    "        \n",
    "        # Create estimator object\n",
    "        self.estimator = KMeans(n_clusters=self.n_clusters, \n",
    "                                init=self._means, verbose=self.verbose, \n",
    "                                random_state=self.random_state, n_jobs=-1)\n",
    "            \n",
    "        self.estimator.fit(X)\n",
    "            \n",
    "        # Set `labels_` attribute for future steps\n",
    "        self.labels_ = self.estimator.labels_\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''Returns X.\n",
    "            \n",
    "        Implemented so that this estimator may be used\n",
    "        as intermediate step in pipeline.\n",
    "        '''\n",
    "        # Verify estimator has been fitted\n",
    "        assert self.labels_ is not None, 'Estimator is not fitted yet.'\n",
    "        \n",
    "        # Create dataframe containing dates associated with clusters\n",
    "        return labeled_data_joiner(X, self.labels_, self.pca_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class allows us to use `means_` from the previous step to initialize the clustering on the transformed weighted returns space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pipeline consists of five named steps. The first two steps are [`FunctionTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer)s. The first step implements `transform_returns`; the second step implements [`date_extractor`](https://github.com/rcorrero/thermidor/blob/master/thermidor/functions/date_extractor.py) from `thermidor`. The third step implements 'decomposer'; the fourth step `GMMSocketCV`; and the fifth and final step `KMeansSocket`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeled_data_joiner(df, labels, step_name):\n",
    "    '''Creates a Pandas datafrme associating\n",
    "    dates with the clusters to which they belong\n",
    "    \n",
    "    These clusters should be mutually-exclusive \n",
    "    partitions of the data space.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : array-like\n",
    "    \n",
    "    labels : \n",
    "        Labels of each point\n",
    "    '''\n",
    "    # Extract `index_` from 'decomposer'\n",
    "    dates = returns_pipeline.named_steps[step_name].index_\n",
    "\n",
    "    # Create dataframe\n",
    "    labeled_data = pd.DataFrame({'dates': dates, \n",
    "                                 'cluster': labels})\n",
    "    \n",
    "    return labeled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is structured such that the first three steps transform the data so that it may be used by the fourth step, `GMMSocketCV`, to select the optimal number of clusters. This value, along with the estimated cluster `means_`, are supplied to the fifth step, `KMeansSocketCV`, for segmentation of the data space. The fourth step simply returns `X`, i.e. the input data array, when `transform` is called on the pipeline. Finally, in the fifth step `labeled_data_joiner` creates a dataframe containing dates and the clusters to which they belong when `transform` is called on `KMeansSocket`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================PIPELINE=================================== #\n",
    "\n",
    "# Pipeline : raw data->dates labeled by cluster\n",
    "#            membership\n",
    "returns_pipeline = Pipeline([\n",
    "    ('preprocessor', \n",
    "     FunctionTransformer(func=transform_returns, kw_args={'alpha' : 1.0},\n",
    "                        validate=False)\n",
    "    ),\n",
    "    \n",
    "    ('date_selector',\n",
    "     FunctionTransformer(func=date_extractor, \n",
    "                         kw_args={'start_date' : 20070101, \n",
    "                                  'end_date' : 20180101}, \n",
    "                         validate=False)\n",
    "    ),\n",
    "    \n",
    "    # RandomizedSearchCV with PCA and uniform param dist\n",
    "    ('decomposer',\n",
    "     decomposer\n",
    "    ), \n",
    "    \n",
    "    # RandomizedSearchCV with GMM and uniform param dist\n",
    "    ('density_estimator',\n",
    "     density_estimator\n",
    "    ), \n",
    "    \n",
    "    # KMeans with init=GMM.means_\n",
    "    ('segmenter',\n",
    "     KMeansSocket(pca_name='decomposer', gmm_name='density_estimator', \n",
    "                  cv=5, n_jobs=-1, random_state=0, verbose=10) \n",
    "    ),],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# ===============================PIPELINE=================================== #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude by fitting `returns_pipeline` on the data, then transforming the data to obtain a Pandas datafrme associating dates with the clusters to which they belong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 1 of 5) Processing preprocessor, total= 1.8min\n",
      "[Pipeline] ..... (step 2 of 5) Processing date_selector, total=   0.4s\n",
      "[Pipeline] ........ (step 3 of 5) Processing decomposer, total=  14.5s\n",
      "[Pipeline] . (step 4 of 5) Processing density_estimator, total= 7.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/cluster/k_means_.py:969: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=10\n",
      "  return_n_iter=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 5 of 5) Processing segmenter, total=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20070103</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20070104</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20070105</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20070108</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20070109</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dates  cluster\n",
       "0  20070103      193\n",
       "1  20070104      184\n",
       "2  20070105      120\n",
       "3  20070108      120\n",
       "4  20070109       25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = returns_pipeline.fit_transform(spdata)\n",
    "\n",
    "results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['cluster'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that 'density_estimator' converged to an interior local optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_components</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.275088</td>\n",
       "      <td>8.084099</td>\n",
       "      <td>0.782277</td>\n",
       "      <td>0.114390</td>\n",
       "      <td>173</td>\n",
       "      <td>{'n_components': 173}</td>\n",
       "      <td>698.043250</td>\n",
       "      <td>700.260140</td>\n",
       "      <td>701.768663</td>\n",
       "      <td>702.309288</td>\n",
       "      <td>702.342351</td>\n",
       "      <td>700.944234</td>\n",
       "      <td>1.636018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.698776</td>\n",
       "      <td>3.827563</td>\n",
       "      <td>0.218641</td>\n",
       "      <td>0.078357</td>\n",
       "      <td>48</td>\n",
       "      <td>{'n_components': 48}</td>\n",
       "      <td>697.972549</td>\n",
       "      <td>699.999603</td>\n",
       "      <td>701.433332</td>\n",
       "      <td>702.135186</td>\n",
       "      <td>702.170483</td>\n",
       "      <td>700.741715</td>\n",
       "      <td>1.592569</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.268614</td>\n",
       "      <td>13.792442</td>\n",
       "      <td>0.596621</td>\n",
       "      <td>0.139212</td>\n",
       "      <td>118</td>\n",
       "      <td>{'n_components': 118}</td>\n",
       "      <td>698.031370</td>\n",
       "      <td>700.191331</td>\n",
       "      <td>701.711581</td>\n",
       "      <td>702.303237</td>\n",
       "      <td>702.288906</td>\n",
       "      <td>700.904785</td>\n",
       "      <td>1.630291</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.636353</td>\n",
       "      <td>6.493906</td>\n",
       "      <td>0.858106</td>\n",
       "      <td>0.111587</td>\n",
       "      <td>193</td>\n",
       "      <td>{'n_components': 193}</td>\n",
       "      <td>698.064915</td>\n",
       "      <td>699.967070</td>\n",
       "      <td>701.794602</td>\n",
       "      <td>702.399716</td>\n",
       "      <td>702.396000</td>\n",
       "      <td>700.923929</td>\n",
       "      <td>1.684860</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.571593</td>\n",
       "      <td>6.006373</td>\n",
       "      <td>1.413904</td>\n",
       "      <td>0.481144</td>\n",
       "      <td>252</td>\n",
       "      <td>{'n_components': 252}</td>\n",
       "      <td>698.083161</td>\n",
       "      <td>699.872747</td>\n",
       "      <td>701.875363</td>\n",
       "      <td>702.427298</td>\n",
       "      <td>702.451668</td>\n",
       "      <td>700.941502</td>\n",
       "      <td>1.713115</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41.123506</td>\n",
       "      <td>5.275619</td>\n",
       "      <td>0.715745</td>\n",
       "      <td>0.198404</td>\n",
       "      <td>196</td>\n",
       "      <td>{'n_components': 196}</td>\n",
       "      <td>698.088541</td>\n",
       "      <td>700.271743</td>\n",
       "      <td>701.837146</td>\n",
       "      <td>702.412356</td>\n",
       "      <td>702.371592</td>\n",
       "      <td>700.995779</td>\n",
       "      <td>1.648344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.531050</td>\n",
       "      <td>0.798068</td>\n",
       "      <td>0.043952</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_components': 10}</td>\n",
       "      <td>698.038652</td>\n",
       "      <td>699.810812</td>\n",
       "      <td>700.721808</td>\n",
       "      <td>701.616611</td>\n",
       "      <td>701.835582</td>\n",
       "      <td>700.404176</td>\n",
       "      <td>1.383282</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29.210389</td>\n",
       "      <td>5.303723</td>\n",
       "      <td>0.527719</td>\n",
       "      <td>0.025291</td>\n",
       "      <td>212</td>\n",
       "      <td>{'n_components': 212}</td>\n",
       "      <td>698.097922</td>\n",
       "      <td>699.822278</td>\n",
       "      <td>701.808713</td>\n",
       "      <td>702.393864</td>\n",
       "      <td>702.378724</td>\n",
       "      <td>700.899766</td>\n",
       "      <td>1.688688</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33.916793</td>\n",
       "      <td>5.359555</td>\n",
       "      <td>0.605268</td>\n",
       "      <td>0.038104</td>\n",
       "      <td>243</td>\n",
       "      <td>{'n_components': 243}</td>\n",
       "      <td>698.069009</td>\n",
       "      <td>700.154265</td>\n",
       "      <td>701.774298</td>\n",
       "      <td>702.448885</td>\n",
       "      <td>702.478420</td>\n",
       "      <td>700.984436</td>\n",
       "      <td>1.684665</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.513413</td>\n",
       "      <td>5.525443</td>\n",
       "      <td>0.141828</td>\n",
       "      <td>0.079421</td>\n",
       "      <td>88</td>\n",
       "      <td>{'n_components': 88}</td>\n",
       "      <td>698.094484</td>\n",
       "      <td>699.736294</td>\n",
       "      <td>701.660454</td>\n",
       "      <td>702.243103</td>\n",
       "      <td>702.234091</td>\n",
       "      <td>700.793165</td>\n",
       "      <td>1.632893</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      39.275088      8.084099         0.782277        0.114390   \n",
       "1      22.698776      3.827563         0.218641        0.078357   \n",
       "2      39.268614     13.792442         0.596621        0.139212   \n",
       "3      42.636353      6.493906         0.858106        0.111587   \n",
       "4      57.571593      6.006373         1.413904        0.481144   \n",
       "5      41.123506      5.275619         0.715745        0.198404   \n",
       "6       2.531050      0.798068         0.043952        0.009193   \n",
       "7      29.210389      5.303723         0.527719        0.025291   \n",
       "8      33.916793      5.359555         0.605268        0.038104   \n",
       "9      14.513413      5.525443         0.141828        0.079421   \n",
       "\n",
       "  param_n_components                 params  split0_test_score  \\\n",
       "0                173  {'n_components': 173}         698.043250   \n",
       "1                 48   {'n_components': 48}         697.972549   \n",
       "2                118  {'n_components': 118}         698.031370   \n",
       "3                193  {'n_components': 193}         698.064915   \n",
       "4                252  {'n_components': 252}         698.083161   \n",
       "5                196  {'n_components': 196}         698.088541   \n",
       "6                 10   {'n_components': 10}         698.038652   \n",
       "7                212  {'n_components': 212}         698.097922   \n",
       "8                243  {'n_components': 243}         698.069009   \n",
       "9                 88   {'n_components': 88}         698.094484   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0         700.260140         701.768663         702.309288         702.342351   \n",
       "1         699.999603         701.433332         702.135186         702.170483   \n",
       "2         700.191331         701.711581         702.303237         702.288906   \n",
       "3         699.967070         701.794602         702.399716         702.396000   \n",
       "4         699.872747         701.875363         702.427298         702.451668   \n",
       "5         700.271743         701.837146         702.412356         702.371592   \n",
       "6         699.810812         700.721808         701.616611         701.835582   \n",
       "7         699.822278         701.808713         702.393864         702.378724   \n",
       "8         700.154265         701.774298         702.448885         702.478420   \n",
       "9         699.736294         701.660454         702.243103         702.234091   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0       700.944234        1.636018                3  \n",
       "1       700.741715        1.592569                9  \n",
       "2       700.904785        1.630291                6  \n",
       "3       700.923929        1.684860                5  \n",
       "4       700.941502        1.713115                4  \n",
       "5       700.995779        1.648344                1  \n",
       "6       700.404176        1.383282               10  \n",
       "7       700.899766        1.688688                7  \n",
       "8       700.984436        1.684665                2  \n",
       "9       700.793165        1.632893                8  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(returns_pipeline.named_steps['density_estimator'].model_selector.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_pipeline.named_steps['decomposer'].best_estimator_.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'decomposer' also converged to an interior optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_components</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.586388</td>\n",
       "      <td>0.038964</td>\n",
       "      <td>0.087358</td>\n",
       "      <td>0.011440</td>\n",
       "      <td>173</td>\n",
       "      <td>{'n_components': 173}</td>\n",
       "      <td>2645.751393</td>\n",
       "      <td>3478.510667</td>\n",
       "      <td>3642.794648</td>\n",
       "      <td>3663.358353</td>\n",
       "      <td>3372.918210</td>\n",
       "      <td>3360.662230</td>\n",
       "      <td>373.258844</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.328776</td>\n",
       "      <td>0.024337</td>\n",
       "      <td>0.071195</td>\n",
       "      <td>0.016092</td>\n",
       "      <td>48</td>\n",
       "      <td>{'n_components': 48}</td>\n",
       "      <td>3020.505832</td>\n",
       "      <td>3458.110956</td>\n",
       "      <td>3578.479676</td>\n",
       "      <td>3534.200656</td>\n",
       "      <td>3420.986617</td>\n",
       "      <td>3402.450055</td>\n",
       "      <td>198.866057</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.488257</td>\n",
       "      <td>0.064381</td>\n",
       "      <td>0.073576</td>\n",
       "      <td>0.035197</td>\n",
       "      <td>118</td>\n",
       "      <td>{'n_components': 118}</td>\n",
       "      <td>2896.864241</td>\n",
       "      <td>3499.315763</td>\n",
       "      <td>3633.235772</td>\n",
       "      <td>3615.363811</td>\n",
       "      <td>3416.932871</td>\n",
       "      <td>3412.340834</td>\n",
       "      <td>269.609316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.865544</td>\n",
       "      <td>0.015245</td>\n",
       "      <td>0.095711</td>\n",
       "      <td>0.028548</td>\n",
       "      <td>193</td>\n",
       "      <td>{'n_components': 193}</td>\n",
       "      <td>2642.763416</td>\n",
       "      <td>3485.494776</td>\n",
       "      <td>3639.290875</td>\n",
       "      <td>3666.347759</td>\n",
       "      <td>3356.398086</td>\n",
       "      <td>3358.059582</td>\n",
       "      <td>374.773868</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.369138</td>\n",
       "      <td>0.078269</td>\n",
       "      <td>0.145202</td>\n",
       "      <td>0.033313</td>\n",
       "      <td>324</td>\n",
       "      <td>{'n_components': 324}</td>\n",
       "      <td>2782.815085</td>\n",
       "      <td>3460.696684</td>\n",
       "      <td>3673.454159</td>\n",
       "      <td>3696.149230</td>\n",
       "      <td>3223.245252</td>\n",
       "      <td>3367.324096</td>\n",
       "      <td>338.567264</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.045230</td>\n",
       "      <td>0.081108</td>\n",
       "      <td>0.117069</td>\n",
       "      <td>0.021342</td>\n",
       "      <td>252</td>\n",
       "      <td>{'n_components': 252}</td>\n",
       "      <td>2671.924018</td>\n",
       "      <td>3488.460009</td>\n",
       "      <td>3654.820436</td>\n",
       "      <td>3686.176063</td>\n",
       "      <td>3346.777193</td>\n",
       "      <td>3369.639797</td>\n",
       "      <td>369.653124</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.794813</td>\n",
       "      <td>0.091752</td>\n",
       "      <td>0.085547</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>196</td>\n",
       "      <td>{'n_components': 196}</td>\n",
       "      <td>2648.784404</td>\n",
       "      <td>3493.759913</td>\n",
       "      <td>3638.082975</td>\n",
       "      <td>3669.794691</td>\n",
       "      <td>3356.107364</td>\n",
       "      <td>3361.307747</td>\n",
       "      <td>373.438223</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.619385</td>\n",
       "      <td>0.014269</td>\n",
       "      <td>0.113431</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>360</td>\n",
       "      <td>{'n_components': 360}</td>\n",
       "      <td>2765.899970</td>\n",
       "      <td>3427.000640</td>\n",
       "      <td>3682.417387</td>\n",
       "      <td>3709.606421</td>\n",
       "      <td>3152.947890</td>\n",
       "      <td>3347.644749</td>\n",
       "      <td>353.801557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.267322</td>\n",
       "      <td>0.034829</td>\n",
       "      <td>0.053388</td>\n",
       "      <td>0.015275</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_components': 10}</td>\n",
       "      <td>3133.083991</td>\n",
       "      <td>3313.671185</td>\n",
       "      <td>3487.968132</td>\n",
       "      <td>3472.161338</td>\n",
       "      <td>3436.535088</td>\n",
       "      <td>3368.659443</td>\n",
       "      <td>132.738313</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.632351</td>\n",
       "      <td>0.104432</td>\n",
       "      <td>0.058541</td>\n",
       "      <td>0.019148</td>\n",
       "      <td>212</td>\n",
       "      <td>{'n_components': 212}</td>\n",
       "      <td>2655.162673</td>\n",
       "      <td>3497.685966</td>\n",
       "      <td>3630.769878</td>\n",
       "      <td>3676.416894</td>\n",
       "      <td>3366.284324</td>\n",
       "      <td>3365.263578</td>\n",
       "      <td>371.305498</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.586388      0.038964         0.087358        0.011440   \n",
       "1       0.328776      0.024337         0.071195        0.016092   \n",
       "2       0.488257      0.064381         0.073576        0.035197   \n",
       "3       0.865544      0.015245         0.095711        0.028548   \n",
       "4       1.369138      0.078269         0.145202        0.033313   \n",
       "5       1.045230      0.081108         0.117069        0.021342   \n",
       "6       0.794813      0.091752         0.085547        0.035533   \n",
       "7       0.619385      0.014269         0.113431        0.013393   \n",
       "8       0.267322      0.034829         0.053388        0.015275   \n",
       "9       0.632351      0.104432         0.058541        0.019148   \n",
       "\n",
       "  param_n_components                 params  split0_test_score  \\\n",
       "0                173  {'n_components': 173}        2645.751393   \n",
       "1                 48   {'n_components': 48}        3020.505832   \n",
       "2                118  {'n_components': 118}        2896.864241   \n",
       "3                193  {'n_components': 193}        2642.763416   \n",
       "4                324  {'n_components': 324}        2782.815085   \n",
       "5                252  {'n_components': 252}        2671.924018   \n",
       "6                196  {'n_components': 196}        2648.784404   \n",
       "7                360  {'n_components': 360}        2765.899970   \n",
       "8                 10   {'n_components': 10}        3133.083991   \n",
       "9                212  {'n_components': 212}        2655.162673   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0        3478.510667        3642.794648        3663.358353        3372.918210   \n",
       "1        3458.110956        3578.479676        3534.200656        3420.986617   \n",
       "2        3499.315763        3633.235772        3615.363811        3416.932871   \n",
       "3        3485.494776        3639.290875        3666.347759        3356.398086   \n",
       "4        3460.696684        3673.454159        3696.149230        3223.245252   \n",
       "5        3488.460009        3654.820436        3686.176063        3346.777193   \n",
       "6        3493.759913        3638.082975        3669.794691        3356.107364   \n",
       "7        3427.000640        3682.417387        3709.606421        3152.947890   \n",
       "8        3313.671185        3487.968132        3472.161338        3436.535088   \n",
       "9        3497.685966        3630.769878        3676.416894        3366.284324   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0      3360.662230      373.258844                8  \n",
       "1      3402.450055      198.866057                2  \n",
       "2      3412.340834      269.609316                1  \n",
       "3      3358.059582      374.773868                9  \n",
       "4      3367.324096      338.567264                5  \n",
       "5      3369.639797      369.653124                3  \n",
       "6      3361.307747      373.438223                7  \n",
       "7      3347.644749      353.801557               10  \n",
       "8      3368.659443      132.738313                4  \n",
       "9      3365.263578      371.305498                6  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(returns_pipeline.named_steps['decomposer'].model_selector.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because both cross-validation steps found interior optima, we feel confident that the parameter distributions over which the model optimizes are appropriate, and the model does not need to be modified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We include the model's code in one cell for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Sci-kit Learn\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# thermidor\n",
    "from thermidor import EstimatorSocketCV\n",
    "from thermidor import ClustererSocket\n",
    "from thermidor import date_extractor\n",
    "\n",
    "\n",
    "def transform_returns(df, alpha=1.0):\n",
    "    '''Extracts weighted returns data from\n",
    "    CRSP raw data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : array-like\n",
    "    \n",
    "    alpha : float, optional default=1.0\n",
    "        Real number to multiply weighted returns by.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Pandas dataframe containing weighted returns.\n",
    "    '''\n",
    "    # Pivot the raw data since assets are stacked\n",
    "    df = pd.pivot(df, \n",
    "                  values = ['BIDLO', 'ASKHI', 'VOL', 'RETX'], \n",
    "                  index='date', columns = 'PERMNO'\n",
    "                 )\n",
    "    \n",
    "    # Infers objects; those that can't be inferred are\n",
    "    # converted to `NaN`\n",
    "    df = df.convert_objects(convert_numeric=True)\n",
    "    \n",
    "    # Replace all missing entries with '0'\n",
    "    df.replace('NaN',0)\n",
    "    \n",
    "    # Functions for `vectorize` to apply elementwise to\n",
    "    # pairs of elements from columns\n",
    "    average = lambda x, y : ((x + y) / 2.0)\n",
    "    \n",
    "    multiply = lambda x, y : (x * y)\n",
    "    \n",
    "    divide = lambda x, y : (x / y)\n",
    "    \n",
    "    permnos = df['RETX'].columns.tolist()\n",
    "    \n",
    "    for permno in permnos:\n",
    "        # Step 1 - Calculate midprice\n",
    "        df[('MIDPRCE', permno)] = np.vectorize(average)(df[('ASKHI', permno)],\n",
    "                                                        df[('BIDLO', permno)])\n",
    "        \n",
    "        # Step 2 - Calculate midprice dollar-value traded\n",
    "        df[('DLRTRDED', permno)] = np.vectorize(multiply)(df[('MIDPRCE', permno)],\n",
    "                                                          df[('VOL', permno)])\n",
    "        \n",
    "    # Sum total dollar-value traded by day\n",
    "    df['TTLDLRTRDED'] = df['DLRTRDED'].sum(axis=1)\n",
    "    \n",
    "    # Drop indexes containing '0' entries in 'TTLDLRTRDED'\n",
    "    # These are days with no market activity\n",
    "    df.drop(df.index[df['TTLDLRTRDED'] == 0], inplace=True)\n",
    "    \n",
    "    for permno in permnos:\n",
    "        # Step 3 - Calculate the percentage of total dollar-value traded\n",
    "        df[('PRCNTDLRTRDED', permno)] = np.vectorize(divide)(df[('DLRTRDED', permno)], \n",
    "                                                             df['TTLDLRTRDED'])\n",
    "        \n",
    "        # Step 4 - Calculate weighted return\n",
    "        df[('WGHTEDRETX', permno)] = alpha * np.vectorize(multiply)(\n",
    "            df[('PRCNTDLRTRDED', permno)], df[('RETX', permno)])\n",
    "    \n",
    "    # Sort dataframe by PERMNO\n",
    "    df = df.sort_index(axis=1, level=1)\n",
    "    \n",
    "    # Only return weighted returns\n",
    "    X = df['WGHTEDRETX']\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def pca_dist(df, proportion=.8):\n",
    "    '''Creates scipy randint distribution\n",
    "    with max=min(n_samples, n_features) of\n",
    "    df.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : array-like\n",
    "    \n",
    "    proportion : float, optional default=.8\n",
    "        Determines the maximum of the range for the distribution.\n",
    "        Defaults to .8 since 5-fold cross-validation uses at most \n",
    "        80 percent of the data.\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    scipy.stats object\n",
    "    '''    \n",
    "    n_samples = df.shape[0] * proportion\n",
    "    \n",
    "    n_features = df.shape[1]\n",
    "    \n",
    "    dist_max = min(n_samples, n_features)\n",
    "    \n",
    "    return randint(1, dist_max)\n",
    "\n",
    "\n",
    "# See:\n",
    "# https://github.com/rcorrero/thermidor/blob/master/thermidor/classes/estimator_socket_cv.py\n",
    "class GMMSocketCV(EstimatorSocketCV):\n",
    "    '''Adds `means_` attribute for use in `returns_pipeline`.\n",
    "    '''\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        '''Fits estimator using `cross_val`.\n",
    "        '''\n",
    "        # Distribution passed to `cross_val`\n",
    "        self.dist = {\n",
    "            self.param_name : self.dist_func(X)\n",
    "        }\n",
    "        \n",
    "        # Create cross-validator object\n",
    "        self.model_selector = self.cross_val(self.estimator, self.dist,\n",
    "                                             cv=self.cv, n_jobs=self.n_jobs,\n",
    "                                             random_state=self.random_state,\n",
    "                                             verbose=self.verbose)\n",
    "        \n",
    "        self.model_selector.fit(X, y, **kwargs)\n",
    "        \n",
    "        # Store `best_estimator_`\n",
    "        self.best_estimator_ = self.model_selector.best_estimator_\n",
    "        \n",
    "        # Store `means_` for use in pipeline\n",
    "        self.means_ = self.best_estimator_.means_\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''Returns X.\n",
    "        \n",
    "        Implemented so that this estimator may be used\n",
    "        as intermediate step in pipeline.\n",
    "        '''\n",
    "        return X\n",
    "\n",
    "\n",
    "def gmm_dist(df, proportion=.8):\n",
    "    '''Creates scipy randint distribution\n",
    "    with max=(n_samples * proportion) of df.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : array-like\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    scipy.stats object\n",
    "    '''\n",
    "    # Determines the maximum of the range for the distribution\n",
    "    proportion = .1\n",
    "    \n",
    "    dist_max = df.shape[0] * proportion\n",
    "    \n",
    "    return randint(1, dist_max)\n",
    "\n",
    "\n",
    "# See:\n",
    "# https://github.com/rcorrero/thermidor/blob/master/thermidor/classes/clusterer_socket.py\n",
    "class KMeansSocket(ClustererSocket):\n",
    "    '''Class which allows for passing `means_`\n",
    "    into `KMeans` from `GaussianMixtureModel`\n",
    "    [or any other object which has a `means_`\n",
    "    attribute].\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    pca_name : string\n",
    "        Name of pipeline step from which `index_` is extracted.\n",
    "        \n",
    "    gmm_name : string\n",
    "            Name of pipeline step from which `means_` is extracted.\n",
    "            \n",
    "    labels_ : list of strings, optional default=None\n",
    "        Labels of each point.\n",
    "        \n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "        - None, to use the default 3-fold cross validation,\n",
    "        - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
    "        - :term:`CV splitter`,\n",
    "        - An iterable yielding (train, test) splits as arrays of indices.\n",
    "        For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
    "        either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
    "        other cases, :class:`KFold` is used.\n",
    "            \n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "            \n",
    "    random_state : int, RandomState instance or None, optional, default=None\n",
    "        Pseudo random number generator state used for random uniform sampling\n",
    "        from lists of possible values instead of scipy.stats distributions.\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`.\n",
    "            \n",
    "    verbose : integer\n",
    "        Controls the verbosity: the higher, the more messages.\n",
    "    '''\n",
    "    def __init__(self, pca_name=None, gmm_name=None, labels_=None,\n",
    "                 cv=3, n_jobs=None, random_state=None, verbose=False):\n",
    "        self.pca_name = pca_name\n",
    "        self.gmm_name = gmm_name\n",
    "        self.labels_ = labels_\n",
    "        \n",
    "        self.cv = cv\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        '''Fits `KMeans` using `means_`\n",
    "        from `gmm_name` step in pipeline.\n",
    "        '''\n",
    "        self.pipeline = returns_pipeline\n",
    "            \n",
    "        # Extract `means_` from previous step in pipeline\n",
    "        self._means = self.pipeline.named_steps[\n",
    "            self.gmm_name].means_\n",
    "        \n",
    "        # Calculate number of clusters\n",
    "        self.n_clusters = self._means.shape[0]\n",
    "        \n",
    "        # Create estimator object\n",
    "        self.estimator = KMeans(n_clusters=self.n_clusters, \n",
    "                                init=self._means, verbose=self.verbose, \n",
    "                                random_state=self.random_state, n_jobs=-1)\n",
    "            \n",
    "        self.estimator.fit(X)\n",
    "            \n",
    "        # Set `labels_` attribute for future steps\n",
    "        self.labels_ = self.estimator.labels_\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''Returns X.\n",
    "            \n",
    "        Implemented so that this estimator may be used\n",
    "        as intermediate step in pipeline.\n",
    "        '''\n",
    "        # Verify estimator has been fitted\n",
    "        assert self.labels_ is not None, 'Estimator is not fitted yet.'\n",
    "        \n",
    "        # Create dataframe containing dates associated with clusters\n",
    "        return labeled_data_joiner(X, self.labels_, self.pca_name)\n",
    "\n",
    "\n",
    "def labeled_data_joiner(df, labels, step_name):\n",
    "    '''Creates a Pandas datafrme associating\n",
    "    dates with the clusters to which they belong\n",
    "    \n",
    "    These clusters should be mutually-exclusive \n",
    "    partitions of the data space.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : array-like\n",
    "    \n",
    "    labels : \n",
    "        Labels of each point\n",
    "    '''\n",
    "    # Extract `index_` from 'decomposer'\n",
    "    dates = returns_pipeline.named_steps[step_name].index_\n",
    "\n",
    "    # Create dataframe\n",
    "    labeled_data = pd.DataFrame({'dates': dates, \n",
    "                                 'cluster': labels})\n",
    "    \n",
    "    return labeled_data\n",
    "\n",
    "\n",
    "# ===============================PIPELINE=================================== #\n",
    "\n",
    "# Pipeline : raw data->dates labeled by cluster\n",
    "#            membership\n",
    "returns_pipeline = Pipeline([\n",
    "    ('preprocessor', \n",
    "     FunctionTransformer(func=transform_returns, kw_args={'alpha' : 1.0},\n",
    "                         validate=False)\n",
    "    ),\n",
    "    \n",
    "    ('date_selector',\n",
    "     FunctionTransformer(func=date_extractor, \n",
    "                         kw_args={'start_date' : 20070101, \n",
    "                                  'end_date' : 20180101}, \n",
    "                         validate=False)\n",
    "    ),\n",
    "    \n",
    "    # RandomizedSearchCV with PCA and uniform param dist\n",
    "    ('decomposer',\n",
    "     EstimatorSocketCV(estimator=PCA(), param_name='n_components',\n",
    "                       dist_func=pca_dist, cross_val=RandomizedSearchCV,\n",
    "                       cv=5, n_jobs=-1, random_state=0)\n",
    "    ), \n",
    "    \n",
    "    # RandomizedSearchCV with GMM and uniform param dist\n",
    "    ('density_estimator',\n",
    "     GMMSocketCV(estimator=GaussianMixture(), \n",
    "                 param_name='n_components',\n",
    "                 dist_func=gmm_dist,\n",
    "                 cross_val=RandomizedSearchCV,\n",
    "                 cv=5, n_jobs=-1, random_state=0)\n",
    "    ), \n",
    "    \n",
    "    # KMeans with init=GMM.means_\n",
    "    ('segmenter',\n",
    "     KMeansSocket(pca_name='decomposer', gmm_name='density_estimator', \n",
    "                  cv=5, n_jobs=-1, random_state=0, verbose=10) \n",
    "    ),],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# ===============================PIPELINE=================================== #\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
